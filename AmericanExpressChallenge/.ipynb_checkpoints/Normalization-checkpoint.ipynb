{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sn\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv', names=list(map(str, range(56))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447095</td>\n",
       "      <td>3452</td>\n",
       "      <td>111</td>\n",
       "      <td>22</td>\n",
       "      <td>433</td>\n",
       "      <td>214</td>\n",
       "      <td>3677</td>\n",
       "      <td>252</td>\n",
       "      <td>210</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113427</td>\n",
       "      <td>3093</td>\n",
       "      <td>95</td>\n",
       "      <td>9</td>\n",
       "      <td>124</td>\n",
       "      <td>7</td>\n",
       "      <td>4115</td>\n",
       "      <td>234</td>\n",
       "      <td>227</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66435</td>\n",
       "      <td>2551</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>726</td>\n",
       "      <td>231</td>\n",
       "      <td>202</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8957</td>\n",
       "      <td>2944</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>430</td>\n",
       "      <td>13</td>\n",
       "      <td>1868</td>\n",
       "      <td>224</td>\n",
       "      <td>238</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>434631</td>\n",
       "      <td>3030</td>\n",
       "      <td>327</td>\n",
       "      <td>34</td>\n",
       "      <td>277</td>\n",
       "      <td>101</td>\n",
       "      <td>1973</td>\n",
       "      <td>120</td>\n",
       "      <td>181</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1    2   3    4    5     6    7    8    9 ...  46  47  48  49  \\\n",
       "0  447095  3452  111  22  433  214  3677  252  210   74 ...   0   0   0   0   \n",
       "1  113427  3093   95   9  124    7  4115  234  227  124 ...   0   0   0   0   \n",
       "2   66435  2551   61  17   90    5   726  231  202   98 ...   0   0   0   0   \n",
       "3    8957  2944  135   3  430   13  1868  224  238  149 ...   0   0   0   0   \n",
       "4  434631  3030  327  34  277  101  1973  120  181  190 ...   0   1   0   0   \n",
       "\n",
       "   50  51  52  53  54  55  \n",
       "0   0   0   0   1   0   0  \n",
       "1   0   0   0   0   0   1  \n",
       "2   0   0   0   0   0   1  \n",
       "3   0   0   0   0   0   1  \n",
       "4   0   0   0   0   0   1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "      <td>406709.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>290590.177164</td>\n",
       "      <td>2959.547492</td>\n",
       "      <td>155.865518</td>\n",
       "      <td>14.099390</td>\n",
       "      <td>269.789478</td>\n",
       "      <td>46.520906</td>\n",
       "      <td>2351.535781</td>\n",
       "      <td>212.115648</td>\n",
       "      <td>223.336223</td>\n",
       "      <td>142.591322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089951</td>\n",
       "      <td>0.077975</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.026953</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.015144</td>\n",
       "      <td>0.487712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>167743.065591</td>\n",
       "      <td>279.765009</td>\n",
       "      <td>111.973194</td>\n",
       "      <td>7.479914</td>\n",
       "      <td>212.657586</td>\n",
       "      <td>58.393568</td>\n",
       "      <td>1561.097709</td>\n",
       "      <td>26.754036</td>\n",
       "      <td>19.751245</td>\n",
       "      <td>38.260251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286112</td>\n",
       "      <td>0.268132</td>\n",
       "      <td>0.052428</td>\n",
       "      <td>0.056511</td>\n",
       "      <td>0.014874</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.161946</td>\n",
       "      <td>0.152151</td>\n",
       "      <td>0.122124</td>\n",
       "      <td>0.499850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1859.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-173.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>145203.000000</td>\n",
       "      <td>2809.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>290625.000000</td>\n",
       "      <td>2996.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>435909.000000</td>\n",
       "      <td>3163.000000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>3329.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>581012.000000</td>\n",
       "      <td>3858.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>7116.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0              1              2              3  \\\n",
       "count  406709.000000  406709.000000  406709.000000  406709.000000   \n",
       "mean   290590.177164    2959.547492     155.865518      14.099390   \n",
       "std    167743.065591     279.765009     111.973194       7.479914   \n",
       "min         1.000000    1859.000000       0.000000       0.000000   \n",
       "25%    145203.000000    2809.000000      58.000000       9.000000   \n",
       "50%    290625.000000    2996.000000     127.000000      13.000000   \n",
       "75%    435909.000000    3163.000000     261.000000      18.000000   \n",
       "max    581012.000000    3858.000000     360.000000      66.000000   \n",
       "\n",
       "                   4              5              6              7  \\\n",
       "count  406709.000000  406709.000000  406709.000000  406709.000000   \n",
       "mean      269.789478      46.520906    2351.535781     212.115648   \n",
       "std       212.657586      58.393568    1561.097709      26.754036   \n",
       "min         0.000000    -173.000000       0.000000       0.000000   \n",
       "25%       108.000000       7.000000    1106.000000     198.000000   \n",
       "50%       218.000000      30.000000    1995.000000     218.000000   \n",
       "75%       390.000000      69.000000    3329.000000     231.000000   \n",
       "max      1397.000000     601.000000    7116.000000     254.000000   \n",
       "\n",
       "                   8              9      ...                   46  \\\n",
       "count  406709.000000  406709.000000      ...        406709.000000   \n",
       "mean      223.336223     142.591322      ...             0.089951   \n",
       "std        19.751245      38.260251      ...             0.286112   \n",
       "min         0.000000       0.000000      ...             0.000000   \n",
       "25%       213.000000     119.000000      ...             0.000000   \n",
       "50%       226.000000     143.000000      ...             0.000000   \n",
       "75%       237.000000     168.000000      ...             0.000000   \n",
       "max       254.000000     254.000000      ...             1.000000   \n",
       "\n",
       "                  47             48             49             50  \\\n",
       "count  406709.000000  406709.000000  406709.000000  406709.000000   \n",
       "mean        0.077975       0.002756       0.003204       0.000221   \n",
       "std         0.268132       0.052428       0.056511       0.014874   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  51             52             53             54  \\\n",
       "count  406709.000000  406709.000000  406709.000000  406709.000000   \n",
       "mean        0.000479       0.026953       0.023712       0.015144   \n",
       "std         0.021891       0.161946       0.152151       0.122124   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  55  \n",
       "count  406709.000000  \n",
       "mean        0.487712  \n",
       "std         0.499850  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b4eeaf080>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD4CAYAAAAQP7oXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFP1JREFUeJzt3X+MnVed3/H3Z+0NoqXZGDKJXNups+zsdkPUGmKBJcSKkpI4abUOFWmTP4hLIxloIi3a/YOw/SMsEAlasUiRICvTuHEqSEgJKNbWNGu52UWrJpAJpPlByHpismSwlQw4hFTZhjp8+8c9AzeTOzPHM8bX4PdLurrP/T7nnOfcyNFHz3meO0+qCkmSevzauCcgSfrlYWhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSeq2etwTON7OPPPM2rhx47inIUm/VB544IEfVNXEUu1+5UJj48aNTE1NjXsakvRLJcnf9rRzeUqS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUrdfuR/3/bLYeN1/H/cUfqU8+Yl/Me4pSKcEzzQkSd0MDUlSN0NDktTN0JAkdVsyNJJsSHJPkseSPJrkD1r9tUn2JTnQ3te0epLcmGQ6yUNJ3jQ01vbW/kCS7UP1C5I83PrcmCSLHUOSNB49ZxpHgT+qqt8FtgDXJDkPuA7YX1WTwP72GeASYLK9dgA3wSAAgOuBtwBvBq4fCoGbWtu5fltbfaFjSJLGYMnQqKrDVfXNtv088BiwDtgG7G7NdgOXte1twK01cB9wRpK1wMXAvqo6UlXPAvuArW3f6VV1b1UVcOu8sUYdQ5I0Bsd0TSPJRuCNwNeBs6vqMAyCBTirNVsHPDXUbabVFqvPjKizyDEkSWPQHRpJXgPcCXywqn68WNMRtVpGvVuSHUmmkkzNzs4eS1dJ0jHo+kV4kl9nEBifr6ovt/LTSdZW1eG2xPRMq88AG4a6rwcOtfrb59X/stXXj2i/2DFepqp2AjsBNm/efEyBI2mej/zGuGfwq+Ujz417BsdVz91TAW4GHquqPx3atQeYuwNqO3DXUP2qdhfVFuC5trR0N3BRkjXtAvhFwN1t3/NJtrRjXTVvrFHHkCSNQc+ZxluB9wAPJ3mw1f4Y+ARwR5Krge8Bl7d9e4FLgWngBeC9AFV1JMnHgPtbu49W1ZG2/QHgFuDVwFfbi0WOIUkagyVDo6r+mtHXHQAuHNG+gGsWGGsXsGtEfQo4f0T9h6OOIUkaD38RLknqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKlbz+NedyV5JskjQ7UvJnmwvZ6ce6Jfko1J/m5o358N9bkgycNJppPc2B7tSpLXJtmX5EB7X9Pqae2mkzyU5E3H/+tLko5Fz5nGLcDW4UJV/Zuq2lRVm4A7gS8P7X5ibl9VvX+ofhOwA5hsr7kxrwP2V9UksL99BrhkqO2O1l+SNEZLhkZVfQ04MmpfO1v418Bti42RZC1welXd2x4HeytwWdu9DdjdtnfPq99aA/cBZ7RxJEljstJrGm8Dnq6qA0O1c5N8K8lfJXlbq60DZobazLQawNlVdRigvZ811OepBfq8TJIdSaaSTM3Ozq7sG0mSFrTS0LiSl59lHAbOqao3An8IfCHJ6UBG9K0lxu7uU1U7q2pzVW2emJjomLYkaTlWL7djktXAvwIumKtV1YvAi237gSRPAL/N4Cxh/VD39cChtv10krVVdbgtPz3T6jPAhgX6SJLGYCVnGv8c+E5V/WzZKclEklVt+zcZXMQ+2Jadnk+ypV0HuQq4q3XbA2xv29vn1a9qd1FtAZ6bW8aSJI1Hzy23twH3Ar+TZCbJ1W3XFbzyAvjvAQ8l+d/Al4D3V9XcRfQPAP8ZmAaeAL7a6p8A3pnkAPDO9hlgL3Cwtf8c8O+P/etJko6nJZenqurKBer/dkTtTga34I5qPwWcP6L+Q+DCEfUCrllqfpKkE8dfhEuSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnq1vPkvl1JnknyyFDtI0m+n+TB9rp0aN+Hk0wneTzJxUP1ra02neS6ofq5Sb6e5ECSLyY5rdVf1T5Pt/0bj9eXliQtT8+Zxi3A1hH1T1fVpvbaC5DkPAaPgX1D6/PZJKvac8M/A1wCnAdc2doCfLKNNQk8C8w9TvZq4Nmq+i3g062dJGmMlgyNqvoacGSpds024PaqerGqvsvg+d5vbq/pqjpYVT8Bbge2JQnwDgbPEwfYDVw2NNbutv0l4MLWXpI0Jiu5pnFtkofa8tWaVlsHPDXUZqbVFqq/DvhRVR2dV3/ZWG3/c639KyTZkWQqydTs7OwKvpIkaTHLDY2bgNcDm4DDwKdafdSZQC2jvthYryxW7ayqzVW1eWJiYrF5S5JWYFmhUVVPV9VLVfVT4HMMlp9gcKawYajpeuDQIvUfAGckWT2v/rKx2v7foH+ZTJL0C7Cs0Eiydujju4C5O6v2AFe0O5/OBSaBbwD3A5PtTqnTGFws31NVBdwDvLv13w7cNTTW9rb9buB/tvaSpDFZvVSDJLcBbwfOTDIDXA+8PckmBstFTwLvA6iqR5PcAXwbOApcU1UvtXGuBe4GVgG7qurRdogPAbcn+TjwLeDmVr8Z+K9JphmcYVyx4m8rSVqRJUOjqq4cUb55RG2u/Q3ADSPqe4G9I+oH+fny1nD9/wKXLzU/SdKJ4y/CJUndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHVbMjSS7EryTJJHhmr/Kcl3kjyU5CtJzmj1jUn+LsmD7fVnQ30uSPJwkukkNyZJq782yb4kB9r7mlZPazfdjvOm4//1JUnHoudM4xZg67zaPuD8qvonwN8AHx7a90RVbWqv9w/VbwJ2MHhu+OTQmNcB+6tqEtjfPgNcMtR2R+svSRqjJUOjqr7G4Bndw7W/qKqj7eN9wPrFxkiyFji9qu6tqgJuBS5ru7cBu9v27nn1W2vgPuCMNo4kaUyOxzWNfwd8dejzuUm+leSvkryt1dYBM0NtZloN4OyqOgzQ3s8a6vPUAn1eJsmOJFNJpmZnZ1f2bSRJC1pRaCT5D8BR4POtdBg4p6reCPwh8IUkpwMZ0b2WGr63T1XtrKrNVbV5YmKib/KSpGO2erkdk2wH/iVwYVtyoqpeBF5s2w8keQL4bQZnCcNLWOuBQ2376SRrq+pwW356ptVngA0L9JEkjcGyzjSSbAU+BPx+Vb0wVJ9Isqpt/yaDi9gH27LT80m2tLumrgLuat32ANvb9vZ59avaXVRbgOfmlrEkSeOx5JlGktuAtwNnJpkBrmdwt9SrgH3tztn72p1Svwd8NMlR4CXg/VU1dxH9AwzuxHo1g2sgc9dBPgHckeRq4HvA5a2+F7gUmAZeAN67ki8qSVq5JUOjqq4cUb55gbZ3AncusG8KOH9E/YfAhSPqBVyz1PwkSSeOvwiXJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1K0rNJLsSvJMkkeGaq9Nsi/Jgfa+ptWT5MYk00keSvKmoT7bW/sD7Rnjc/ULkjzc+tzYHgm74DEkSePRe6ZxC7B1Xu06YH9VTQL722eASxg8G3wS2AHcBIMAYPCo2LcAbwauHwqBm1rbuX5blziGJGkMukKjqr4GHJlX3gbsbtu7gcuG6rfWwH3AGUnWAhcD+6rqSFU9C+wDtrZ9p1fVve0Rr7fOG2vUMSRJY7CSaxpnV9VhgPZ+VquvA54aajfTaovVZ0bUFzvGyyTZkWQqydTs7OwKvpIkaTG/iAvhGVGrZdS7VdXOqtpcVZsnJiaOpask6RisJDSebktLtPdnWn0G2DDUbj1waIn6+hH1xY4hSRqDlYTGHmDuDqjtwF1D9avaXVRbgOfa0tLdwEVJ1rQL4BcBd7d9zyfZ0u6aumreWKOOIUkag9U9jZLcBrwdODPJDIO7oD4B3JHkauB7wOWt+V7gUmAaeAF4L0BVHUnyMeD+1u6jVTV3cf0DDO7QejXw1fZikWNIksagKzSq6soFdl04om0B1ywwzi5g14j6FHD+iPoPRx1DkjQe/iJcktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUrdlh0aS30ny4NDrx0k+mOQjSb4/VL90qM+Hk0wneTzJxUP1ra02neS6ofq5Sb6e5ECSLyY5bflfVZK0UssOjap6vKo2VdUm4AIGj3b9Stv96bl9VbUXIMl5wBXAG4CtwGeTrEqyCvgMcAlwHnBlawvwyTbWJPAscPVy5ytJWrnjtTx1IfBEVf3tIm22AbdX1YtV9V0GzxB/c3tNV9XBqvoJcDuwLUmAdwBfav13A5cdp/lKkpbheIXGFcBtQ5+vTfJQkl1J1rTaOuCpoTYzrbZQ/XXAj6rq6Lz6KyTZkWQqydTs7OzKv40kaaQVh0a7zvD7wH9rpZuA1wObgMPAp+aajuhey6i/sli1s6o2V9XmiYmJY5i9JOlYrD4OY1wCfLOqngaYewdI8jngz9vHGWDDUL/1wKG2Par+A+CMJKvb2cZwe0nSGByP5akrGVqaSrJ2aN+7gEfa9h7giiSvSnIuMAl8A7gfmGx3Sp3GYKlrT1UVcA/w7tZ/O3DXcZivJGmZVnSmkeTvAe8E3jdU/o9JNjFYSnpybl9VPZrkDuDbwFHgmqp6qY1zLXA3sArYVVWPtrE+BNye5OPAt4CbVzJfSdLKrCg0quoFBhesh2vvWaT9DcANI+p7gb0j6gcZ3F0lSToJ+ItwSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1Ox7PCH8yycNJHkwy1WqvTbIvyYH2vqbVk+TGJNNJHkrypqFxtrf2B5JsH6pf0Mafbn1HPTtcknQCHK8zjX9WVZuqanP7fB2wv6omgf3tMwyeJz7ZXjuAm2AQMsD1wFsYPHTp+rmgaW12DPXbepzmLEk6Rr+o5altwO62vRu4bKh+aw3cB5zRnil+MbCvqo5U1bPAPmBr23d6Vd3bnhl+69BYkqQT7HiERgF/keSBJDta7eyqOgzQ3s9q9XXAU0N9Z1ptsfrMiLokaQxW9Izw5q1VdSjJWcC+JN9ZpO2o6xG1jPrLBx2E1Q6Ac845Z+kZS5KWZcVnGlV1qL0/A3yFwTWJp9vSEu39mdZ8Btgw1H09cGiJ+voR9flz2FlVm6tq88TExEq/kiRpASsKjSR/P8k/mNsGLgIeAfYAc3dAbQfuatt7gKvaXVRbgOfa8tXdwEVJ1rQL4BcBd7d9zyfZ0u6aumpoLEnSCbbS5amzga+0u2BXA1+oqv+R5H7gjiRXA98DLm/t9wKXAtPAC8B7AarqSJKPAfe3dh+tqiNt+wPALcCrga+2lyRpDFYUGlV1EPinI+o/BC4cUS/gmgXG2gXsGlGfAs5fyTwlSceHvwiXJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1G3ZoZFkQ5J7kjyW5NEkf9DqH0ny/SQPttelQ30+nGQ6yeNJLh6qb2216STXDdXPTfL1JAeSfDHJacudryRp5VZypnEU+KOq+l1gC3BNkvPavk9X1ab22gvQ9l0BvAHYCnw2yaokq4DPAJcA5wFXDo3zyTbWJPAscPUK5itJWqFlh0ZVHa6qb7bt54HHgHWLdNkG3F5VL1bVdxk8J/zN7TVdVQer6ifA7cC2DB48/g7gS63/buCy5c5XkrRyx+WaRpKNwBuBr7fStUkeSrIryZpWWwc8NdRtptUWqr8O+FFVHZ1XlySNyYpDI8lrgDuBD1bVj4GbgNcDm4DDwKfmmo7oXsuoj5rDjiRTSaZmZ2eP8RtIknqtKDSS/DqDwPh8VX0ZoKqerqqXquqnwOcYLD/B4Exhw1D39cChReo/AM5Isnpe/RWqamdVba6qzRMTEyv5SpKkRazk7qkANwOPVdWfDtXXDjV7F/BI294DXJHkVUnOBSaBbwD3A5PtTqnTGFws31NVBdwDvLv13w7ctdz5SpJWbvXSTRb0VuA9wMNJHmy1P2Zw99MmBktJTwLvA6iqR5PcAXybwZ1X11TVSwBJrgXuBlYBu6rq0Tbeh4Dbk3wc+BaDkJIkjcmyQ6Oq/prR1x32LtLnBuCGEfW9o/pV1UF+vrwlSRozfxEuSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqdtJHxpJtiZ5PMl0kuvGPR9JOpWd1KGRZBXwGeAS4DwGj5I9b7yzkqRT10kdGgwe9TpdVQer6ifA7cC2Mc9Jkk5Zy35G+AmyDnhq6PMM8Jb5jZLsAHa0j/8nyeMnYG6nijOBH4x7EkvJJ8c9A43BL8W/Tf4k455Br3/U0+hkD41R/7XrFYWqncDOX/x0Tj1Jpqpq87jnIc3nv83xONmXp2aADUOf1wOHxjQXSTrlneyhcT8wmeTcJKcBVwB7xjwnSTplndTLU1V1NMm1wN3AKmBXVT065mmdalz208nKf5tjkKpXXCKQJGmkk315SpJ0EjE0JEndDA1JUreT+kK4Tqwk/5jBL+7XMfg9zCFgT1U9NtaJSTppeKYhAJJ8iMGfaQnwDQa3Owe4zT8UKWmOd08JgCR/A7yhqv7fvPppwKNVNTmemUmLS/Leqvov457HqcIzDc35KfAPR9TXtn3SyepPxj2BU4nXNDTng8D+JAf4+R+JPAf4LeDasc1KApI8tNAu4OwTOZdTnctT+pkkv8bgz9GvY/A/4wxwf1W9NNaJ6ZSX5GngYuDZ+buA/1VVo86S9QvgmYZ+pqp+Ctw37nlII/w58JqqenD+jiR/eeKnc+ryTEOS1M0L4ZKkboaGJKmboSFJ6mZoSJK6/X92kZLm4BXmfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(train['55']).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, cols):\n",
    "    norms = dict()\n",
    "    for col in cols:\n",
    "        norm = StandardScaler()\n",
    "        norm.fit(np.array(df[col]).reshape(-1,1))\n",
    "        df[col] = norm.transform(np.array(df[col]).reshape(-1, 1))\n",
    "        norms[col] = norm\n",
    "    return df, norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_csv(model, test_data, ids, filename):\n",
    "    preds = model.predict_proba(test_data)\n",
    "    first_col = preds[:, 1]\n",
    "    df = pd.DataFrame.from_items([('key', ids), ('score', first_col)])\n",
    "    df.to_csv(filename, index=False)\n",
    "    print('CSV saved successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(model, val_x, val_y):\n",
    "    yhat = model.predict(val_x)\n",
    "    print(accuracy_score(yhat, val_y))\n",
    "    print(roc_auc_score(yhat, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/parv/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "train_normed, norms = normalize(train.copy(), list(map(str, range(1, 11))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " '2': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " '3': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " '4': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " '5': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " '6': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " '7': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " '8': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " '9': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " '10': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447095</td>\n",
       "      <td>1.760238</td>\n",
       "      <td>-0.400681</td>\n",
       "      <td>1.056245</td>\n",
       "      <td>0.767481</td>\n",
       "      <td>2.868112</td>\n",
       "      <td>0.849060</td>\n",
       "      <td>1.490781</td>\n",
       "      <td>-0.675210</td>\n",
       "      <td>-1.792759</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113427</td>\n",
       "      <td>0.477017</td>\n",
       "      <td>-0.543573</td>\n",
       "      <td>-0.681745</td>\n",
       "      <td>-0.685561</td>\n",
       "      <td>-0.676803</td>\n",
       "      <td>1.129632</td>\n",
       "      <td>0.817984</td>\n",
       "      <td>0.185496</td>\n",
       "      <td>-0.485918</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66435</td>\n",
       "      <td>-1.460326</td>\n",
       "      <td>-0.847217</td>\n",
       "      <td>0.387787</td>\n",
       "      <td>-0.845442</td>\n",
       "      <td>-0.711054</td>\n",
       "      <td>-1.041279</td>\n",
       "      <td>0.705851</td>\n",
       "      <td>-1.080248</td>\n",
       "      <td>-1.165475</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8957</td>\n",
       "      <td>-0.055573</td>\n",
       "      <td>-0.186344</td>\n",
       "      <td>-1.483895</td>\n",
       "      <td>0.753374</td>\n",
       "      <td>-0.574052</td>\n",
       "      <td>-0.309741</td>\n",
       "      <td>0.444208</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>434631</td>\n",
       "      <td>0.251828</td>\n",
       "      <td>1.528354</td>\n",
       "      <td>2.660543</td>\n",
       "      <td>0.033907</td>\n",
       "      <td>0.932965</td>\n",
       "      <td>-0.242481</td>\n",
       "      <td>-3.443060</td>\n",
       "      <td>-2.143474</td>\n",
       "      <td>1.239112</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6  \\\n",
       "0  447095  1.760238 -0.400681  1.056245  0.767481  2.868112  0.849060   \n",
       "1  113427  0.477017 -0.543573 -0.681745 -0.685561 -0.676803  1.129632   \n",
       "2   66435 -1.460326 -0.847217  0.387787 -0.845442 -0.711054 -1.041279   \n",
       "3    8957 -0.055573 -0.186344 -1.483895  0.753374 -0.574052 -0.309741   \n",
       "4  434631  0.251828  1.528354  2.660543  0.033907  0.932965 -0.242481   \n",
       "\n",
       "          7         8         9 ...  46  47  48  49  50  51  52  53  54  55  \n",
       "0  1.490781 -0.675210 -1.792759 ...   0   0   0   0   0   0   0   1   0   0  \n",
       "1  0.817984  0.185496 -0.485918 ...   0   0   0   0   0   0   0   0   0   1  \n",
       "2  0.705851 -1.080248 -1.165475 ...   0   0   0   0   0   0   0   0   0   1  \n",
       "3  0.444208  0.742424  0.167502 ...   0   0   0   0   0   0   0   0   0   1  \n",
       "4 -3.443060 -2.143474  1.239112 ...   0   1   0   0   0   0   0   0   0   1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_normed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = list(map(str, range(1, 55)))\n",
    "X = train_normed[feat_cols]\n",
    "y = train_normed['55']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, random_state=45, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565833148926754\n",
      "0.7567381842474961\n"
     ]
    }
   ],
   "source": [
    "scores(logreg, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7839738388532369\n",
      "0.7858537841580313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "scores(xgbc, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
